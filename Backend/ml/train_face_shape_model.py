"""
YÃ¼z Åekli SÄ±nÄ±flandÄ±rma - CNN Model EÄŸitimi

Kaggle Face Shape Dataset kullanÄ±larak eÄŸitilmiÅŸ bir CNN modeli.
Dataset: https://www.kaggle.com/datasets/niten19/face-shape-dataset

KullanÄ±m:
1. Kaggle'dan veri setini indir
2. backend/ml/data/ klasÃ¶rÃ¼ne Ã§Ä±kart
3. Bu scripti Ã§alÄ±ÅŸtÄ±r: python train_face_shape_model.py
"""

import os
import sys
import numpy as np
from PIL import ImageFile

# Bozuk/kesik gÃ¶rÃ¼ntÃ¼leri tolere et
ImageFile.LOAD_TRUNCATED_IMAGES = True

# TensorFlow import
os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'

# TF ve Keras import
import tensorflow as tf
from tensorflow import keras
layers = keras.layers
Sequential = keras.Sequential
ImageDataGenerator = keras.preprocessing.image.ImageDataGenerator
EarlyStopping = keras.callbacks.EarlyStopping
ModelCheckpoint = keras.callbacks.ModelCheckpoint
Adam = keras.optimizers.Adam
print(f"TensorFlow version: {tf.__version__}")

import matplotlib
matplotlib.use('Agg')  # GUI olmadan Ã§alÄ±ÅŸmasÄ± iÃ§in
import matplotlib.pyplot as plt
import json
from datetime import datetime

# Ayarlar
IMG_SIZE = (128, 128)
BATCH_SIZE = 32
EPOCHS = 50
NUM_CLASSES = 5  # Heart, Oblong, Oval, Round, Square

# Veri seti yolu
DATA_DIR = os.path.join(os.path.dirname(__file__), 'FaceShape Dataset')
MODEL_DIR = os.path.join(os.path.dirname(__file__), 'models')

# KlasÃ¶r oluÅŸtur
os.makedirs(MODEL_DIR, exist_ok=True)


def create_cnn_model():
    """CNN modeli oluÅŸtur"""
    model = Sequential([
        # Input layer
        layers.Input(shape=(IMG_SIZE[0], IMG_SIZE[1], 3)),
        
        # Conv Block 1
        layers.Conv2D(32, (3, 3), activation='relu', padding='same'),
        layers.BatchNormalization(),
        layers.Conv2D(32, (3, 3), activation='relu', padding='same'),
        layers.MaxPooling2D((2, 2)),
        layers.Dropout(0.25),
        
        # Conv Block 2
        layers.Conv2D(64, (3, 3), activation='relu', padding='same'),
        layers.BatchNormalization(),
        layers.Conv2D(64, (3, 3), activation='relu', padding='same'),
        layers.MaxPooling2D((2, 2)),
        layers.Dropout(0.25),
        
        # Conv Block 3
        layers.Conv2D(128, (3, 3), activation='relu', padding='same'),
        layers.BatchNormalization(),
        layers.Conv2D(128, (3, 3), activation='relu', padding='same'),
        layers.MaxPooling2D((2, 2)),
        layers.Dropout(0.25),
        
        # Conv Block 4
        layers.Conv2D(256, (3, 3), activation='relu', padding='same'),
        layers.BatchNormalization(),
        layers.MaxPooling2D((2, 2)),
        layers.Dropout(0.25),
        
        # Fully Connected
        layers.Flatten(),
        layers.Dense(512, activation='relu'),
        layers.BatchNormalization(),
        layers.Dropout(0.5),
        layers.Dense(256, activation='relu'),
        layers.Dropout(0.5),
        
        # Output
        layers.Dense(NUM_CLASSES, activation='softmax')
    ])
    
    model.compile(
        optimizer=Adam(learning_rate=0.001),
        loss='categorical_crossentropy',
        metrics=['accuracy']
    )
    
    return model


def load_data():
    """Veri setini yÃ¼kle"""
    train_dir = os.path.join(DATA_DIR, 'training_set')
    test_dir = os.path.join(DATA_DIR, 'testing_set')
    
    if not os.path.exists(train_dir):
        print(f"âŒ Veri seti bulunamadÄ±: {train_dir}")
        print("\nğŸ“¥ LÃ¼tfen Kaggle'dan veri setini indirin:")
        print("   https://www.kaggle.com/datasets/niten19/face-shape-dataset")
        print(f"\nğŸ“ Ve ÅŸu klasÃ¶re Ã§Ä±kartÄ±n: {DATA_DIR}")
        return None, None
    
    # Data augmentation (shear_range kaldÄ±rÄ±ldÄ± - scipy uyumluluk sorunu)
    train_datagen = ImageDataGenerator(
        rescale=1./255,
        rotation_range=15,
        width_shift_range=0.1,
        height_shift_range=0.1,
        zoom_range=0.1,
        horizontal_flip=True,
        fill_mode='nearest',
        validation_split=0.2
    )
    
    test_datagen = ImageDataGenerator(rescale=1./255)
    
    # Training data
    train_generator = train_datagen.flow_from_directory(
        train_dir,
        target_size=IMG_SIZE,
        batch_size=BATCH_SIZE,
        class_mode='categorical',
        subset='training',
        shuffle=True
    )
    
    # Validation data
    val_generator = train_datagen.flow_from_directory(
        train_dir,
        target_size=IMG_SIZE,
        batch_size=BATCH_SIZE,
        class_mode='categorical',
        subset='validation',
        shuffle=False
    )
    
    # Test data
    test_generator = test_datagen.flow_from_directory(
        test_dir,
        target_size=IMG_SIZE,
        batch_size=BATCH_SIZE,
        class_mode='categorical',
        shuffle=False
    )
    
    print(f"\nğŸ“Š Veri Seti Bilgileri:")
    print(f"   EÄŸitim: {train_generator.samples} gÃ¶rÃ¼ntÃ¼")
    print(f"   DoÄŸrulama: {val_generator.samples} gÃ¶rÃ¼ntÃ¼")
    print(f"   Test: {test_generator.samples} gÃ¶rÃ¼ntÃ¼")
    print(f"   SÄ±nÄ±flar: {train_generator.class_indices}")
    
    return (train_generator, val_generator, test_generator), train_generator.class_indices


def train_model(model, data):
    """Modeli eÄŸit"""
    train_gen, val_gen, test_gen = data
    
    # Callbacks
    callbacks = [
        EarlyStopping(
            monitor='val_loss',
            patience=10,
            restore_best_weights=True,
            verbose=1
        ),
        ModelCheckpoint(
            os.path.join(MODEL_DIR, 'face_shape_best.keras'),
            monitor='val_accuracy',
            save_best_only=True,
            verbose=1
        )
    ]
    
    print("\nğŸš€ EÄŸitim baÅŸlÄ±yor...")
    
    history = model.fit(
        train_gen,
        epochs=EPOCHS,
        validation_data=val_gen,
        callbacks=callbacks,
        verbose=1
    )
    
    return history, test_gen


def evaluate_model(model, test_gen, class_indices):
    """Modeli deÄŸerlendir"""
    print("\nğŸ“ˆ Model DeÄŸerlendirmesi:")
    
    # Test accuracy
    test_loss, test_acc = model.evaluate(test_gen, verbose=0)
    print(f"   Test Loss: {test_loss:.4f}")
    print(f"   Test Accuracy: {test_acc:.4f} ({test_acc*100:.1f}%)")
    
    # Predictions
    predictions = model.predict(test_gen, verbose=0)
    y_pred = np.argmax(predictions, axis=1)
    y_true = test_gen.classes
    
    # Class names
    class_names = {v: k for k, v in class_indices.items()}
    
    # Per-class accuracy
    print("\nğŸ“Š SÄ±nÄ±f BazlÄ± Performans:")
    from sklearn.metrics import classification_report, confusion_matrix
    
    report = classification_report(y_true, y_pred, target_names=list(class_indices.keys()))
    print(report)
    
    # Confusion matrix
    cm = confusion_matrix(y_true, y_pred)
    print("\nğŸ“‹ KarÄ±ÅŸÄ±klÄ±k Matrisi:")
    print(cm)
    
    return {
        'test_loss': float(test_loss),
        'test_accuracy': float(test_acc),
        'confusion_matrix': cm.tolist(),
        'class_indices': class_indices
    }


def plot_history(history):
    """EÄŸitim grafiklerini Ã§iz"""
    fig, axes = plt.subplots(1, 2, figsize=(14, 5))
    
    # Accuracy
    axes[0].plot(history.history['accuracy'], label='EÄŸitim')
    axes[0].plot(history.history['val_accuracy'], label='DoÄŸrulama')
    axes[0].set_title('Model DoÄŸruluÄŸu')
    axes[0].set_xlabel('Epoch')
    axes[0].set_ylabel('DoÄŸruluk')
    axes[0].legend()
    axes[0].grid(True)
    
    # Loss
    axes[1].plot(history.history['loss'], label='EÄŸitim')
    axes[1].plot(history.history['val_loss'], label='DoÄŸrulama')
    axes[1].set_title('Model KaybÄ±')
    axes[1].set_xlabel('Epoch')
    axes[1].set_ylabel('KayÄ±p')
    axes[1].legend()
    axes[1].grid(True)
    
    plt.tight_layout()
    plt.savefig(os.path.join(MODEL_DIR, 'training_history.png'), dpi=150)
    print(f"\nğŸ“Š Grafik kaydedildi: {os.path.join(MODEL_DIR, 'training_history.png')}")
    plt.show()


def save_model(model, class_indices, metrics):
    """Modeli ve metadata'yÄ± kaydet"""
    # Model kaydet
    model_path = os.path.join(MODEL_DIR, 'face_shape_model.keras')
    model.save(model_path)
    print(f"\nğŸ’¾ Model kaydedildi: {model_path}")
    
    # TFLite versiyonu (mobil iÃ§in)
    converter = tf.lite.TFLiteConverter.from_keras_model(model)
    tflite_model = converter.convert()
    tflite_path = os.path.join(MODEL_DIR, 'face_shape_model.tflite')
    with open(tflite_path, 'wb') as f:
        f.write(tflite_model)
    print(f"ğŸ’¾ TFLite model kaydedildi: {tflite_path}")
    
    # Metadata kaydet
    metadata = {
        'created_at': datetime.now().isoformat(),
        'img_size': IMG_SIZE,
        'num_classes': NUM_CLASSES,
        'class_indices': class_indices,
        'metrics': metrics
    }
    
    metadata_path = os.path.join(MODEL_DIR, 'model_metadata.json')
    with open(metadata_path, 'w') as f:
        json.dump(metadata, f, indent=2)
    print(f"ğŸ’¾ Metadata kaydedildi: {metadata_path}")


def main():
    print("=" * 60)
    print("YÃœZ ÅEKLÄ° SINIFLANDIRMA - CNN MODEL EÄÄ°TÄ°MÄ°")
    print("=" * 60)
    
    # Veri yÃ¼kle
    data, class_indices = load_data()
    if data is None:
        return
    
    # Model oluÅŸtur
    model = create_cnn_model()
    model.summary()
    
    # EÄŸit
    history, test_gen = train_model(model, data)
    
    # DeÄŸerlendir
    metrics = evaluate_model(model, test_gen, class_indices)
    
    # Grafik Ã§iz
    plot_history(history)
    
    # Kaydet
    save_model(model, class_indices, metrics)
    
    print("\nâœ… EÄŸitim tamamlandÄ±!")


if __name__ == '__main__':
    main()
